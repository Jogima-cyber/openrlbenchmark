# Open RL Benchmark: Comprehensive Tracked Experiments for Reinforcement Learning

Open RL Benchmark is a comprehensive collection of tracked experiments for RL. It aims to make it easier for RL practioners to pull and compare all kinds of metrics from reputable RL libraries like Stable-baselines3, Tianshou, CleanRL, and others.

Check out this [google doc](https://docs.google.com/document/d/1cDI_AMr2QVmkC53dCHFMYwGJtLC8V4p6KdL2wnYPaiI/edit?usp=sharing) for more info and comment.


## Get started

Check out the [Open RL Benchmark reports](https://wandb.ai/openrlbenchmark/openrlbenchmark/reportlist): featuring W&B reports with tracked Atari, MuJoCo experiments from SB3, CleanRL, and others.

You can "fork" these reports and use them in your own workspace. See the following video for a demo, where I used a _newly-created_ W&B account to clone a report from [Open RL Benchmark reports](https://wandb.ai/openrlbenchmark/openrlbenchmark/reportlist) and compared my metrics with the report's metrics.


https://user-images.githubusercontent.com/5555347/167722421-7f6a138e-6374-491a-8d6e-3b0604e73884.mp4


## What's going on right now?

This is a project we are slowly working on. We have already added all benchmark experiments from CleanRL and @araffin is working on adding SB3 benchmark experiments. We don't have a defined timeline yet, but if you want to get involved. Feel free to reach out to me or open an issue.
